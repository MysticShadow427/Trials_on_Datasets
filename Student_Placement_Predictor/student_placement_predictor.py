# -*- coding: utf-8 -*-
"""student_placement_predictor.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12QeFSD8RC6NHLJiDHBXL2Wu5edbKoQGT

# Student Placement Predictor

### The dataset was downloaded from Kaggle data repository [here](https://www.kaggle.com/datasets/tejashvi14/engineering-placements-prediction).The data collected over two years was compiled in a csv file (*collegePlace.csv*) with 8 columns as following-
  1. Age 
  2. Gender
  3. Stream
  4. Internships
  5. CGPA
  6. Hostel
  7. HistoryOfBacklogs
  8. PlacedOrNot

where the 8th column is the label to be predicted

**This is a binary classification task where we need to predict whether the person with given attributes will be placed or not**

### Downloading the csv file and getting it from Google Drive
"""

from google.colab import drive
drive.mount('/content/gdrive', force_remount=True)

"""### Importing packages"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import RepeatedStratifiedKFold
from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import make_pipeline
from imblearn.over_sampling import SMOTE

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neural_network import MLPClassifier
from sklearn.ensemble import StackingClassifier
from sklearn.ensemble import AdaBoostClassifier
from xgboost import XGBClassifier


from sklearn.metrics import accuracy_score
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import ConfusionMatrixDisplay

"""### Reading the csv file"""

df=pd.read_csv('/content/gdrive/MyDrive/collegePlace.csv')
df

df.shape

df.info()

df.describe()

#checking correlaton between the label and the features so we can decide to drop some
df.corr()['PlacedOrNot']

"""### EDA and Feature Engineering"""

# checking missing values
df.isnull().sum()

# duplicate rows
print(df.duplicated().sum())

#drop duplicates
df.drop_duplicates(inplace=True)

# Check if the duplicate rows are removed
print(df.duplicated().sum())

df

df.info()

encoder=LabelEncoder()
gen=encoder.fit_transform(df['Gender'])

df['gender']=gen

df=df.drop('Gender',axis=1)
df

df['stream']=encoder.fit_transform(df['Stream'])
df

df=df.drop('Stream',axis=1)
df

df.info()

# checking whether the dataset is balanced
print(df['PlacedOrNot'].value_counts())
df['PlacedOrNot'].value_counts().plot(kind='bar')

sns.heatmap(df.corr(),annot=True)

sns.set_style('whitegrid')
sns.pairplot(data=df,hue='PlacedOrNot')

# list of categorical variables to plot
cat_vars = ['Gender','Stream']

# create figure with subplots
fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(20, 10))
axs = axs.ravel()

# create barplot for each categorical variable
for i, var in enumerate(cat_vars):
    sns.barplot(x=var, y='PlacedOrNot', data=df, ax=axs[i], estimator=np.mean)
    axs[i].set_xticklabels(axs[i].get_xticklabels(), rotation=90)

# adjust spacing between subplots
fig.tight_layout()

# show plot
plt.show()

df_s=df[df['PlacedOrNot']==1].groupby('Stream').size().reset_index()
stream_vals=df.Stream.value_counts().values
stream_values=np.array([(78/243)*100,(151/243)*100,(87/174)*100,(105/165)*100,(153/160)*100,(85/152)*100])

# pie chart to find out how many of which stream got placed
stream_names=df.Stream.value_counts().index
stream_vals=df.Stream.value_counts().values

plt.pie(stream_values,labels=stream_names,autopct='%1.2f%%');

sns.violinplot(x='CGPA', data=df);

## Count plot
sns.countplot(x="Internships",data=df,palette=['red','blue','yellow','green']);

"""### Splitting the dataset"""

y=df['PlacedOrNot']
X=df.drop('PlacedOrNot',axis=1)

print(y.shape)
print(X.shape)

#splitting dataset into train,test and val 
X_temp,X_test,y_temp,y_test=train_test_split(X,y,test_size=0.2,random_state=2)
X_train,X_val,y_train,y_val=train_test_split(X_temp,y_temp,test_size=0.1,random_state=2)
print(f'Shape of X_train {X_train.shape}')
print(f'Shape of y_train {y_train.shape}')
print(f'Shape of X_val{X_val.shape}')
print(f'Shape of y_val{y_val.shape}')
print(f'Shape of X_test{X_test.shape}')
print(f'Shape of y_test{y_test.shape}')

X_train

"""### Normalizing the data"""

scaler = StandardScaler()

X_train_trf = scaler.fit_transform(X_train)
X_val_trf=scaler.transform(X_val)
X_test_trf = scaler.transform(X_test)

df_train = pd.DataFrame(X_train_trf, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','gender','stream'])
df_train

df_val = pd.DataFrame(X_val_trf, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','gender','stream'])
df_val

df_test = pd.DataFrame(X_test_trf, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','gender','stream'])
df_test

"""### Fitting Logistic Regression with Hyperparameter Tuning """

model = LogisticRegression()
solvers = ['newton-cg', 'lbfgs', 'liblinear']
penalty = ['l2']
c_values = [100, 10, 1.0, 0.1, 0.01]

# define grid search
grid = dict(solver=solvers,penalty=penalty,C=c_values)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)

# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for Mean, Stdev, Param in zip(means, stds, params):
    print("%f (%f) with: %r" % (Mean, Stdev, Param))

clf=LogisticRegression(solver='newton-cg',C=100,n_jobs=-1)

# fitting logisitic regression with the best obtained parameters
clf.fit(df_train,y_train)

y_pred=clf.predict(df_test)
y_train_pred=clf.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred)*100}%')

"""#### Confusion Matrix and Classification Report"""

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test, y_pred, target_names=target_names))

cm = confusion_matrix(y_test, y_pred)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""### Fitting KNN with Hyperparamter Tuning"""

model=KNeighborsClassifier()
n_neighbors=[3,5,7,9,11]

# define grid search
grid = dict(n_neighbors=n_neighbors)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

knn=KNeighborsClassifier(n_neighbors=9)

# fitting with best paramters

knn.fit(df_train,y_train)

y_pred_knn=knn.predict(df_test)
y_train_pred_knn=knn.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_knn)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_knn)*100}%')

"""#### Confusion Matrix and Classification Report"""

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test, y_pred_knn, target_names=target_names))

cm = confusion_matrix(y_test, y_pred_knn)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""### Fitting SVM with Hyperparamter Tuning"""

model=SVC()
kernel = ['poly', 'rbf', 'sigmoid']
C = [50, 10, 1.0, 0.1, 0.01]
gamma = ['scale']

# define grid search
grid = dict(kernel=kernel,C=C,gamma=gamma)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

svc=SVC(C=1.0,kernel='rbf',gamma='scale')

#fitting the model with best hyperparamters

svc.fit(df_train,y_train)

y_pred_svc=svc.predict(df_test)
y_train_pred_svc=svc.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_svc)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_svc)*100}%')

"""#### Confusion Matrix and Classification Report"""

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test, y_pred_svc, target_names=target_names))

cm = confusion_matrix(y_test, y_pred_svc)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""The above lines tells us that the model is somewhat overfitting

### Fitting Bagging Decision Tree Classifier with Hyperparameter Tuning
"""

bcdt = BaggingClassifier()
n_estimators = [10, 100, 1000]

# define grid search
grid = dict(n_estimators=n_estimators)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=bcdt, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)
# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

BCDT=BaggingClassifier(n_estimators=1000,n_jobs=-1)

# fitting with best parameters

BCDT.fit(df_train,y_train)

y_pred_bcdt=BCDT.predict(df_test)
y_train_pred_bcdt=BCDT.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_bcdt)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_bcdt)*100}%')

"""The model is clearly overfitting

#### Confusion Matrix and Classification Report
"""

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test, y_pred_bcdt, target_names=target_names))

cm = confusion_matrix(y_test, y_pred_bcdt)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""### Fitting Random Forest with Hyperparameter Tuning"""

model = RandomForestClassifier()
n_estimators = [10, 100, 1000]
max_features = ['sqrt', 'log2']

# define grid search
grid = dict(n_estimators=n_estimators,max_features=max_features)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)

# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

rfc=RandomForestClassifier(max_features='sqrt',n_estimators=100)

rfc.fit(df_train,y_train)

y_pred_rfc=rfc.predict(df_test)
y_train_pred_rfc=rfc.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_rfc)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_rfc)*100}%')

"""We can clearly see that the model is overfitting

#### Confusion Matrix and Classfication Report
"""

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test, y_pred_rfc, target_names=target_names))

cm = confusion_matrix(y_test, y_pred_rfc)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""### Fitting Multilayer Perceptron Model with Hyperparameter Tuning"""

model=MLPClassifier()
activation=['identity','relu','tanh','logistic']
solver=['adam','sgd','lbfgs']
alpha=[0.1,0.01,0.001,0.0001]
learning_rate=['adaptive','constant','invscaling']
hidden_layer_sizes=[(8,),(16,),(32,),(64,),(128,)]

# define grid search
grid = dict(activation=activation,solver=solver,alpha=alpha,learning_rate=learning_rate,hidden_layer_sizes=hidden_layer_sizes)
cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)
grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)
grid_result = grid_search.fit(df_val, y_val)

# summarize results
print("Best: %f using %s" % (grid_result.best_score_, grid_result.best_params_))
means = grid_result.cv_results_['mean_test_score']
stds = grid_result.cv_results_['std_test_score']
params = grid_result.cv_results_['params']
for mean, stdev, param in zip(means, stds, params):
    print("%f (%f) with: %r" % (mean, stdev, param))

MLP=MLPClassifier(activation='logistic',alpha=0.1,hidden_layer_sizes=(16,),learning_rate='constant',solver='lbfgs',max_iter=100)

MLP.fit(df_train,y_train)

y_pred_mlp=MLP.predict(df_test)
y_train_pred_mlp=MLP.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_mlp)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_mlp)*100}%')

"""### Ensemble Learning Stacking Classifier"""

estimators=[
    ('svc',svc),
    ('dt',BCDT),
    ('rf',rfc),
    ('mlp',MLP),
    ('knn',knn)
]

stack_model=StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression()
)

stack_model.fit(df_train,y_train)

y_pred_sm=stack_model.predict(df_test)
y_train_pred_sm=stack_model.predict(df_train)

print(f'Train Accuracy {accuracy_score(y_train,y_train_pred_sm)*100}%')
print(f'Test Accuracy {accuracy_score(y_test,y_pred_sm)*100}%')

"""Accuracy obtained is not so good hence trying to improve accuracy as well as address overfitting.

### Trying SMOTE to oversample
"""

smote=SMOTE(sampling_strategy={1:2000, 0:2000},random_state=42)
X_res_n,y_res_n=smote.fit_resample(X,y)

X_res_n.shape

"""Deciding to drop gender to erase bias."""

X_res_n=X_res_n.drop('gender',axis=1)

X_res_n

X_res_n.describe()

y_res_n

y_res_n.value_counts()

#splitting dataset into train,test and val 
X_temp_n,X_test_n,y_temp_n,y_test_n=train_test_split(X_res_n,y_res_n,test_size=0.2,random_state=2)
X_train_n,X_val_n,y_train_n,y_val_n=train_test_split(X_temp_n,y_temp_n,test_size=0.1,random_state=2)
print(f'Shape of X_train {X_train_n.shape}')
print(f'Shape of y_train {y_train_n.shape}')
print(f'Shape of X_val{X_val_n.shape}')
print(f'Shape of y_val{y_val_n.shape}')
print(f'Shape of X_test{X_test_n.shape}')
print(f'Shape of y_test{y_test_n.shape}')

df_train_new = pd.DataFrame(X_temp_n, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','gender','stream'])
df_train_new

df_test_new = pd.DataFrame(X_test_n, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','gender','stream'])
df_test_new

X_res_train_trf=scaler.fit_transform(X_temp_n)
X_res_test_trf=scaler.fit_transform(X_test_n)

df_test_new_res = pd.DataFrame(X_res_test_trf, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','stream'])
df_test_new_res

df_train_new_res = pd.DataFrame(X_res_train_trf, columns = ['Age','Internships','CGPA','Hostel','HistoryOfBacklogs','stream'])
df_train_new_res

"""### Fitting the above models again

#### Ensemble Model
"""

stacked_model_new=StackingClassifier(
    estimators=estimators,
    final_estimator=LogisticRegression()
)

stacked_model_new.fit(X_temp_n,y_temp_n)

#Without normalization 
y_pred_smn=stacked_model_new.predict(X_test_n)
y_train_pred_smn=stacked_model_new.predict(X_temp_n)

print(f'Train Accuracy {accuracy_score(y_temp_n,y_train_pred_smn)*100}%')
print(f'Test Accuracy {accuracy_score(y_test_n,y_pred_smn)*100}%')

stacked_model_new.fit(df_train_new_res,y_temp_n)

#With normalization 
y_pred_smnn=stacked_model_new.predict(df_test_new_res)
y_train_pred_smnn=stacked_model_new.predict(df_train_new_res)

print(f'Train Accuracy {accuracy_score(y_temp_n,y_train_pred_smnn)*100}%')
print(f'Test Accuracy {accuracy_score(y_test_n,y_pred_smnn)*100}%')

"""### Deciding to drop Hostel feature """

df_train_new_res=df_train_new_res.drop('Hostel',axis=1)
df_test_new_res=df_test_new_res.drop('Hostel',axis=1)

X_temp_n=X_temp_n.drop('Hostel',axis=1)
X_test_n=X_test_n.drop('Hostel',axis=1)

stacked_model_new.fit(X_temp_n,y_temp_n)

#Without normalization 
y_pred_smh=stacked_model_new.predict(X_test_n)
y_train_pred_smh=stacked_model_new.predict(X_temp_n)

print(f'Train Accuracy {accuracy_score(y_temp_n,y_train_pred_smh)*100}%')
print(f'Test Accuracy {accuracy_score(y_test_n,y_pred_smh)*100}%')

"""### XGboost Classifier"""

classifier = XGBClassifier(base_score=0.5,booster='gbtree',colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,
                           grow_policy='depthwise',learning_rate=0.300000012, max_bin=256, max_cat_to_onehot=4,
              max_delta_step=0, max_depth=6, max_leaves=0, min_child_weight=1,num_parallel_tree=1,)

classifier.fit(X_temp_n,y_temp_n)

y_pred_x=classifier.predict(X_test_n)
y_train_pred_x=classifier.predict(X_temp_n)

print(f'Train Accuracy {accuracy_score(y_temp_n,y_train_pred_x)*100}%')
print(f'Test Accuracy {accuracy_score(y_test_n,y_pred_x)*100}%')

print('Classification Report')
target_names = ['Placed','NotPlaced']
print(classification_report(y_test_n, y_pred_x, target_names=target_names))

cm = confusion_matrix(y_test_n, y_pred_x)

disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)

disp.plot(cmap=plt.cm.Reds_r)
print('Displaying Confusion Matrix')
print('==========================================================')
plt.title('Confusion Matrix')
plt.show()
print('==========================================================')

"""Decinding to save this XgBoost Model"""

import pickle
pickle.dump(classifier,open('/content/gdrive/MyDrive/xgb_classifier_final.pkl','wb'))

"""### AdaBoost Classifier"""

estimator=DecisionTreeClassifier(max_depth=None)
clf=AdaBoostClassifier(estimator=estimator,n_estimators=100,random_state=42)
clf.fit(X_temp_n,y_temp_n)

y_pred_ab=clf.predict(X_test_n)
y_train_pred_ab=clf.predict(X_temp_n)

print(f'Train Accuracy {accuracy_score(y_temp_n,y_train_pred_ab)*100}%')
print(f'Test Accuracy {accuracy_score(y_test_n,y_pred_ab)*100}%')
